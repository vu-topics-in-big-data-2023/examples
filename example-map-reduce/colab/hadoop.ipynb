{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hadoop",
      "provenance": [],
      "authorship_tag": "ABX9TyN3ru300LGKe8xfRviPZDR7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vu-topics-in-big-data-2022/examples/blob/main/example-map-reduce/colab/hadoop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8QD8JufDgBB"
      },
      "source": [
        "#install java first\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm4sRuLzDufI"
      },
      "source": [
        "#install hadoop. But we clean up first \n",
        "!rm -rf hadoop-3.3.0.tar.gz hadoop-3.3.0 /usr/local/hadoop\n",
        "#download\n",
        "!wget https://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz\n",
        "#untar\n",
        "!tar -xzvf hadoop-3.3.0.tar.gz >/dev/null\n",
        "!mv hadoop-3.3.0 /usr/local/hadoop\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLIB9e_KE8za"
      },
      "source": [
        "#get the data file\n",
        "!wget https://datasets.imdbws.com/title.basics.tsv.gz\n",
        "!gunzip title.basics.tsv.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ZbiM1nEnMA"
      },
      "source": [
        "#check path and java home\n",
        "!echo $JAVA_HOME\n",
        "os.environ[\"PATH\"]+= os.pathsep + \"/usr/local/hadoop/bin\"\n",
        "!echo $PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSzAtzFJFkap"
      },
      "source": [
        "#check hadoop execution and ensure its in path\n",
        "!/usr/local/hadoop/bin/hadoop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik9RbcTyt4AF"
      },
      "source": [
        "The hadoop process requires a mapper file and reducer file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1bYn6G2GSoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db82ffe-7818-4e96-91a3-edfe8cc6dd18"
      },
      "source": [
        "#the magic command with two %% will take the code in cell and copy to a file.\n",
        "%%file mapper.py\n",
        "#!/usr/bin/python2.7\n",
        "import sys\n",
        "\n",
        "def map_function(title):\n",
        "    fields = title.strip().split('\\t')         # Split title to fields using the data delimeter\n",
        "    primaryTitle = fields[2]                   # Select the required field\n",
        "    for word in primaryTitle.strip().split():  # Split primary title by words\n",
        "        yield word.strip('!\"*#$').lower(), 1                          # Use a word as a key\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "  for line in sys.stdin:\n",
        "      # Call map_function for each line in the input\n",
        "      for key, value in map_function(line):\n",
        "          # Emit key-value pairs using '|' as a delimeter  \n",
        "          print(key + \"|\" + str(value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing mapper.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJGBloFcGlNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1eb331b-605f-4f24-e233-a2f8464adcf6"
      },
      "source": [
        "%%file reducer.py\n",
        "#!/usr/bin/python2.7\n",
        "import sys\n",
        "\n",
        "prev_word = None\n",
        "value_total = 0\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "  for line in sys.stdin:          # For ever line in the input from stdin\n",
        "      line = line.strip()         # Remove trailing characters\n",
        "      word, value = line.split(\"|\", 1)\n",
        "      value = int(value)\n",
        "\n",
        "      # Remember that Hadoop sorts mapper output by key, and the reducer takes these keys sorted\n",
        "      if prev_word == word:\n",
        "          value_total += value\n",
        "      else:\n",
        "          if prev_word != None:  # Write result to stdout\n",
        "              print(prev_word + \"|\" + str(value_total))\n",
        "\n",
        "\n",
        "          value_total = value\n",
        "          prev_word = word\n",
        "\n",
        "  if prev_word == word:  # Don't forget the last key/value pair\n",
        "      print(prev_word + \"|\" + str(value_total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing reducer.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBXsBulVLpC6"
      },
      "source": [
        "#give execute permission and clean output dir\n",
        "!chmod +x mapper.py reducer.py\n",
        "!rm -rf outputdir/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-IWBXSrGv81"
      },
      "source": [
        "#run hadoop\n",
        "!hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input title.basics.tsv -output outputdir -mapper mapper.py -reducer reducer.py -file mapper.py -file reducer.py "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLe3gEm-M5Na",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "632a09d3-9e2f-445c-bbae-a1d7eedec66d"
      },
      "source": [
        "# The output will be created in the outputdir - see the -output flag above\n",
        "!ls -l outputdir/\n",
        "!mv outputdir/part-00000 outputdir/hadoop-out.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 16368\n",
            "-rw-r--r-- 1 root root 16760258 Mar  6 18:46 part-00000\n",
            "-rw-r--r-- 1 root root        0 Mar  6 18:46 _SUCCESS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVwc-_fxNS5g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1a1c6dd3-a76a-472d-fdbc-2886701a9813"
      },
      "source": [
        "#download file\n",
        "from google.colab import files\n",
        "files.download('outputdir/hadoop-out.txt') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_22ad64e4-1b4c-4385-a281-8123d6b0c2ba\", \"hadoop-out.txt\", 16760258)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}